{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5843073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you have to make the module discoverable to load the classes below:\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir('../../../nucleotran/')\n",
    "sys.path.append('./src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1684d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as torch_data\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from models.models import IEAquaticDilated\n",
    "from dataloading.dataloaders import LitCoverageDatasetHDF5\n",
    "from util.load_config import config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c27c67",
   "metadata": {},
   "source": [
    "First, load your model from a checkpoint path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41099336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: interacting metadata column \"proc_age_bin\" has type float or int. Variables like these can easily act as unique sample identifiers.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = Path('/dhc/groups/fglippert/dna_transformers_disentanglement/model_checkpoints/alex/IEAquaticDilated/sweep_b3036x2m/58zi0nkt')\n",
    "model = IEAquaticDilated.load_from_checkpoint(next(checkpoint_dir.glob('*.ckpt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6fa108",
   "metadata": {},
   "source": [
    "#### You can check the model's hyperparameters via the `model.hparams` field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00b608a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"C\":                                   30\n",
       "\"D\":                                   1.5\n",
       "\"L1\":                                  6\n",
       "\"L2\":                                  2\n",
       "\"activation\":                          gelu\n",
       "\"basepath\":                            data/processed/GRCh38/221111_128bp_minoverlap64_mincov2_nc10_tissues\n",
       "\"batch_size\":                          256\n",
       "\"biological_subspace_ratio\":           0.5\n",
       "\"class_freq\":                          None\n",
       "\"coeff_cov\":                           0.01\n",
       "\"cov_and_adv\":                         True\n",
       "\"cov_norm\":                            True\n",
       "\"crop\":                                8\n",
       "\"dilated_residual_dropout\":            0.0\n",
       "\"dilated_residual_kernel_size\":        3\n",
       "\"dim_hidden_discriminator\":            1024\n",
       "\"dim_hidden_embedding\":                256\n",
       "\"dim_random_projections\":              10\n",
       "\"init_bias\":                           None\n",
       "\"input_kernel_size\":                   15\n",
       "\"labels_encoder\":                      False\n",
       "\"linearly_embed_direct_features\":      False\n",
       "\"log_hyperparams\":                     False\n",
       "\"lr\":                                  0.001\n",
       "\"lr_discriminator\":                    0.001\n",
       "\"max_epochs\":                          100\n",
       "\"metadata_loader\":                     <dataloading.metadata.MetadataLoader object at 0x7f9b52cc5940>\n",
       "\"metadata_mapping_config\":             src/config_metadata_target_interactions.yaml\n",
       "\"n_classes\":                           2106\n",
       "\"num_batches_for_variance_estimation\": 1000\n",
       "\"num_hidden_embedding\":                0\n",
       "\"num_hidden_labels_encoder\":           2\n",
       "\"num_random_projections\":              0\n",
       "\"num_steps_discriminator\":             1\n",
       "\"out_pool_type\":                       max\n",
       "\"pointwise_dropout\":                   0.0\n",
       "\"seed_everything\":                     1\n",
       "\"seq_len\":                             2176\n",
       "\"seq_order\":                           2\n",
       "\"tower_kernel_size\":                   5\n",
       "\"use_discriminator\":                   False\n",
       "\"use_intermediate_embedding\":          False\n",
       "\"use_predictor\":                       True\n",
       "\"weight_decay\":                        0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9876b5",
   "metadata": {},
   "source": [
    "### Basic \"manual\" way of obtaining predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce25a6c7",
   "metadata": {},
   "source": [
    "Let's generate some dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3593fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data = torch.randn(100, 16, 2176)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9748ebf3",
   "metadata": {},
   "source": [
    "By passing *return_features=True* to the *forward()* method the model will return all the features in addition to the experiment-level predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "454ca2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 2106])\n",
      "torch.Size([100, 4])\n",
      "torch.Size([100, 2])\n",
      "torch.Size([100, 2])\n"
     ]
    }
   ],
   "source": [
    "predictions, features_all, features_biological, features_technical = model.forward(\n",
    "    x=random_data,\n",
    "    return_features=True,\n",
    ")\n",
    "print(predictions.shape)\n",
    "print(features_all.shape)\n",
    "print(features_biological.shape)\n",
    "print(features_technical.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c793db",
   "metadata": {},
   "source": [
    "### The \"sophisticated\" way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbb55c5",
   "metadata": {},
   "source": [
    "We will use *pytorch_lighning.Trainer* to do the job for us - this is useful when handling large amounts of data, taking care of proper tensor-to-device placement etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07270f96",
   "metadata": {},
   "source": [
    "Let's define a dummy dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56421993",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyDataset(torch_data.Dataset):\n",
    "    def __len__(self):\n",
    "        return 1000\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.randn(16, 2176)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c7ee949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/alek/anaconda3/envs/nucleotran/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288d1e6feb104244ab5180def00be0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer()\n",
    "\n",
    "ret = trainer.predict(\n",
    "    model=model,\n",
    "    dataloaders=torch_data.DataLoader(\n",
    "        dataset=DummyDataset(),\n",
    "        batch_size=128,\n",
    "    ),\n",
    "    # you can also pass a datamodule:\n",
    "    # datamodule=my_datamodule\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85c1c96e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 8\n",
      "Outputs per batch: 4\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of batches: {len(ret)}')\n",
    "print(f'Outputs per batch: {len(ret[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e52a4f",
   "metadata": {},
   "source": [
    "This returns a list of outputs for each batch - we still need to concatenate them into single arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2418b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 2106])\n",
      "torch.Size([1000, 4])\n",
      "torch.Size([1000, 2])\n",
      "torch.Size([1000, 2])\n"
     ]
    }
   ],
   "source": [
    "predictions, features_all, features_biological, features_technical = (\n",
    "    # inner loop - iterate over all returned batches and select the appropriate output type\n",
    "    torch.cat([batch[output_idx] for batch in ret]) \n",
    "    # outer loop - iterate over the 4 output types (predictions and 3 feature types)\n",
    "    for output_idx in range(4)    \n",
    ")\n",
    "\n",
    "print(predictions.shape)\n",
    "print(features_all.shape)\n",
    "print(features_biological.shape)\n",
    "print(features_technical.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4275bb",
   "metadata": {},
   "source": [
    "### Use the ENCODE data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5826fbee",
   "metadata": {},
   "source": [
    "Human \"toy\" data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1a382e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BED-file contains 10000 regions.\n",
      "93.250% of regions have at least 1 label.\n"
     ]
    }
   ],
   "source": [
    "datamodule = LitCoverageDatasetHDF5(\n",
    "    seq_order=2, \n",
    "    seq_len=2176,\n",
    "    basepath=\"data/processed/GRCh38/toydata\",\n",
    "    ref_path=config['reference']['GRCh38'],\n",
    "    batch_size=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eda9cca",
   "metadata": {},
   "source": [
    "Human data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9213975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = LitCoverageDatasetHDF5(\n",
    "    seq_order=2, \n",
    "    seq_len=1152,\n",
    "    basepath=\"data/processed/GRCh38/221111_128bp_minoverlap64_mincov2_nc10_tissues\",\n",
    "    ref_path=config['reference']['GRCh38'],\n",
    "    batch_size=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500a0ee6",
   "metadata": {},
   "source": [
    "Mouse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c178c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = LitCoverageDatasetHDF5(\n",
    "    seq_order=2, \n",
    "    seq_len=2176,\n",
    "    basepath=\"data/processed/mm10/221111_128bp_minoverlap64_mincov2_nc10_tissues\",\n",
    "    ref_path=config['reference']['mm10'],\n",
    "    batch_size=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34f0f7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- Subsetting Info ------------------\n",
      "Subsetting Method: no subsetting \n",
      "\n",
      "Number of samples:\n",
      "available = 10000\n",
      "\tafter subsetting = 10000 (100% of available)\n",
      "\ttraining = 8590 (86% of subset)\n",
      "\tvalidation = 506 (5% of subset)\n",
      "\ttest = 904 (9.04% of subset)\n",
      "for check: missed data in split = 0\n",
      "----------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dhc/home/alexander.rakowski/coldstore/conda_envs/nucleotran/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /dhc/home/alexander.rakowski/coldstore/conda_envs/nu ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/dhc/home/alexander.rakowski/coldstore/conda_envs/nucleotran/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /dhc/home/alexander.rakowski/coldstore/conda_envs/nu ...\n",
      "  rank_zero_warn(\n",
      "You are using a CUDA device ('NVIDIA A40') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 2/2 [00:05<00:00,  2.58s/it]\n"
     ]
    }
   ],
   "source": [
    "def predict_val_collate_fn(batch):\n",
    "    batch = torch.cat([x for x, _ in batch])\n",
    "    return batch\n",
    "\n",
    "\n",
    "datamodule.setup(stage='fit')\n",
    "\n",
    "# choose train_dataloader() or val_dataloader() in 'fit' stage\n",
    "dloader = datamodule.val_dataloader()\n",
    "dloader.collate_fn = predict_val_collate_fn\n",
    "\n",
    "model.eval()\n",
    "trainer = pl.Trainer()\n",
    "ret = trainer.predict(\n",
    "    model=model,\n",
    "    dataloaders=dloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6afde08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([506, 2106])\n",
      "torch.Size([506, 60])\n",
      "torch.Size([506, 30])\n",
      "torch.Size([506, 30])\n"
     ]
    }
   ],
   "source": [
    "predictions, features_all, features_biological, features_technical = (\n",
    "    # inner loop - iterate over all returned batches and select the appropriate output type\n",
    "    torch.cat([batch[output_idx] for batch in ret]) \n",
    "    # outer loop - iterate over the 4 output types (predictions and 3 feature types)\n",
    "    for output_idx in range(4)    \n",
    ")\n",
    "\n",
    "print(predictions.shape)\n",
    "print(features_all.shape)\n",
    "print(features_biological.shape)\n",
    "print(features_technical.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
